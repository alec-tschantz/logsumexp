\documentclass{beamer}
\usepackage{amsmath,amssymb,bm}
\usepackage{graphicx}
\usepackage{natbib}

\title{Attention via $\log \sum \exp$ energy}
\author{Alexander Tschantz}
\date{\today}

\begin{document}

\begin{frame}
    \titlepage
\end{frame}

\begin{frame}{$\log \sum \exp$ energy}
    \begin{itemize}
        \item Define energy function 
        \item Define derivative as softmax (for parent and child)
        \item Softmax paper?
    \end{itemize}
\end{frame}

\begin{frame}{$\log \sum \exp$ graph}
    \begin{itemize}
        \item Gradient descent on hidden states
        \item Gradient descent on parameters of \texttt{sim}
    \end{itemize}
\end{frame}

\begin{frame}{Gaussian mixture model}
    % Content goes here
\end{frame}

\begin{frame}{Categorical mixture mdodel}
    % Content goes here
\end{frame}

\begin{frame}{Hopfield attention}
    % Content goes here
\end{frame}

\begin{frame}{Slot attention}
    % Content goes here
\end{frame}

\begin{frame}{Self attention}
    % Content goes here
\end{frame}

\begin{frame}{Linear mixture model}
    % Content goes here
\end{frame}

\begin{frame}{Non-linear mixture model}
   \begin{itemize}
        \item This is just predictive coding 
        \item Could extend $f(\cdot)$ to be a neural network
   \end{itemize}
\end{frame}

\begin{frame}{Kronecker $\log \sum \exp$ energy}
    % Content goes here
\end{frame}

\begin{frame}{Dual $\log \sum \exp$ energy}
    % Content goes here
\end{frame}

\begin{frame}{Spatio-temporal model}
    % Content goes here
\end{frame}

\begin{frame}{Atari model}
    % Content goes here
\end{frame}

\begin{frame}{Renormalised mixture models}
    % Content goes here
\end{frame}

\begin{frame}{Bayesian model expansion \& reduction}
    % Content goes here
\end{frame}

\begin{frame}{Coordinate ascent}
    % Content goes here
\end{frame}


\begin{frame}{References}
    \bibliographystyle{abbrvnat}
    \bibliography{main}
\end{frame}

\end{document}
